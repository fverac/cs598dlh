{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a177c30-c7b0-42d9-bdd9-46c177ee208c",
   "metadata": {},
   "source": [
    "# CS 598 DLH Final Project\n",
    "\n",
    "**Name:** Fabio Vera\n",
    "\n",
    "**Team:** 133\n",
    "\n",
    "**Project:** 11\n",
    "\n",
    "**Github link:** https://github.com/fverac/cs589dlh\n",
    "\n",
    "**Video link:** https://www.youtube.com/watch?v=ymaahdX9844\n",
    "\n",
    "**Reproducing:** \"Predicting 30-days mortality for MIMIC-III patients with sepsis-3: a machine learning approach using XGboost.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ff74c94b-5e79-4336-a74d-be4cd1bcb978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.base import clone\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, precision_score, \\\n",
    "                            recall_score, f1_score, confusion_matrix, classification_report, \\\n",
    "                            PrecisionRecallDisplay, roc_auc_score, RocCurveDisplay\n",
    "# may have to install xgboost via `pip install xgboost`\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14887c9-6080-4445-b5f4-255c71cf5ece",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<!-- This is an introduction to your report, you should edit this text/mardown section to compose. In this text/markdown, you should introduce:\n",
    "\n",
    "*   Background of the problem\n",
    "  * what type of problem: disease/readmission/mortality prediction,  feature engineeing, data processing, etc\n",
    "  * what is the importance/meaning of solving the problem\n",
    "  * what is the difficulty of the problem\n",
    "  * the state of the art methods and effectiveness.\n",
    "*   Paper explanation\n",
    "  * what did the paper propose\n",
    "  * what is the innovations of the method\n",
    "  * how well the proposed method work (in its own metrics)\n",
    "  * what is the contribution to the reasearch regime (referring the Background above, how important the paper is to the problem). -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f7f8c-5f6b-4a7d-aa88-56da321e48b2",
   "metadata": {},
   "source": [
    "Sepsis accounts for over 5.3 million deaths a year and has an approximate mortality of 30%. With such a high mortality rate, it is desirable to construct an accurate and reliable prognostic (or survival classification) model to inform the allocation of scarce clinical resources. Past attempts at such a prognostic model have either employed traditional predictive methods such as logistic regression, or the use of clinical scoring systems such as Simplified Acute Physiology Score-II. These approaches however, can be limiting in their assumptions or scope of features used for prediction. Machine learning methods such as XGboost may be able to achieve higher performance, with the ability to handle many features and identify nonlinear relationships in the data.\n",
    "\n",
    "The paper I am reproducing proposes using XGBoost for this classification task, and demonstrates improvement in performance over typical models such as logistic regression, achieving an AUC of 0.857 using XGboost vs 0.819 using logistic regression.\n",
    "\n",
    "I will attempt to reproduce their classification experiments, and compare the performance of XGboost on the dataset against traditional methods such as logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdccb95-7824-4baa-8889-6e650dab67c0",
   "metadata": {},
   "source": [
    "# Scope of Reproducibility:\n",
    "\n",
    "<!-- List hypotheses from the paper you will test and the corresponding experiments you will run.\n",
    "\n",
    "\n",
    "1.   Hypothesis 1: xxxxxxx\n",
    "2.   Hypothesis 2: xxxxxxx\n",
    "\n",
    "You can insert images in this notebook text, [see this link](https://stackoverflow.com/questions/50670920/how-to-insert-an-inline-image-in-google-colaboratory-from-google-drive) and example below:\n",
    "\n",
    "![sample_image.png](https://drive.google.com/uc?export=view&id=1g2efvsRJDxTxKz-OY3loMhihrEUdBxbc) -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d20d2c5-6397-4656-b0aa-e9dce2ce29c1",
   "metadata": {},
   "source": [
    "Hypotheses:\n",
    "1. I will see if XGboost can achieve higher performance than logistic regression in sepsis mortality prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9522a404-5f02-4d0b-b47d-c5a364d1e8b4",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671842fd-d3d8-4ef2-9312-e4c77b5dfd26",
   "metadata": {},
   "source": [
    "## Envionment\n",
    "\n",
    "Full environment.yml included in GitHub repo. \n",
    "\n",
    "For convenience, below is a summary of important packages/dependencies:\n",
    "\n",
    "* Python 3.9.12\n",
    "* scikit-learn 1.0.2\n",
    "* pandas 1.4.2\n",
    "* numpy 1.21.5\n",
    "* xgboost 2.0.3\n",
    "* matplotlib 3.5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8c27d5-83a3-4a16-9ccb-d2700baab220",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  Data\n",
    "<!-- Data includes raw data (MIMIC III tables), descriptive statistics (our homework questions), and data processing (feature engineering).\n",
    "  * Source of the data: where the data is collected from; if data is synthetic or self-generated, explain how. If possible, please provide a link to the raw datasets.\n",
    "  * Statistics: include basic descriptive statistics of the dataset like size, cross validation split, label distribution, etc.\n",
    "  * Data process: how do you munipulate the data, e.g., change the class labels, split the dataset to train/valid/test, refining the dataset.\n",
    "  * Illustration: printing results, plotting figures for illustration.\n",
    "  * You can upload your raw dataset to Google Drive and mount this Colab to the same directory. If your raw dataset is too large, you can upload the processed dataset and have a code to load the processed dataset. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438093b9-f079-48ab-8cbc-f6fa5103051d",
   "metadata": {},
   "source": [
    "Data is all from MIMIC III v1.4, which \"is a large, freely-available database comprising deidentified health-related data associated with over forty thousand patients who stayed in critical care units of the Beth Israel Deaconess Medical Center between 2001 and 2012. The database includes information such as demographics, vital sign measurements made at the bedside (~1 data point per hour), laboratory test results, procedures, medications, caregiver notes, imaging reports, and mortality (including post-hospital discharge).\"\n",
    "\n",
    "Data can be obtained from this link after completing the required training.\n",
    "https://physionet.org/content/mimiciii/1.4/\n",
    "\n",
    "Precomputed features like first-day vital signs and many more were obtained from Google BigQuery, which in addition to storing \n",
    "More information as well as underlying code for creating these precomputed/derived tables can be found here: \n",
    "https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iii/concepts\n",
    "\n",
    "Additionally, here are some resources for accessing MIMIC through BigQuery:\n",
    "https://mimic.mit.edu/docs/gettingstarted/cloud/bigquery/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55351f7b-acb6-4511-8571-745631e8efc8",
   "metadata": {},
   "source": [
    "#### Sepsis filters\n",
    "\n",
    "Obtain diagnosis codes for sepsis, to be used for filtering downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c250c55-0111-4e9e-9538-b3d3c32d0b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['99591', '99592', '78552'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# icd9 codes I care about\n",
    "sepsis_codes = (\n",
    "    pd.read_csv(f'mimic-iii-clinical-database-1.4/D_ICD_DIAGNOSES.csv')\n",
    "    .loc[lambda df: df['SHORT_TITLE'].str.lower().isin(['sepsis', 'severe sepsis', 'septic shock'])] #sepsis”, “severe sepsis” and “septic shock”\n",
    "    ['ICD9_CODE']\n",
    "    .values\n",
    ")\n",
    "sepsis_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e8ab54-495d-4819-bba8-5c96074be6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnoses = pd.read_csv('mimic-iii-clinical-database-1.4/DIAGNOSES_ICD.csv')\n",
    "diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76281e39-7e2d-4f89-8a34-198ae5bd0b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sepsis_diagnoses = (\n",
    "    diagnoses\n",
    "    .loc[\n",
    "        lambda df: df['ICD9_CODE'].isin(sepsis_codes)\n",
    "    ]\n",
    ")\n",
    "sepsis_diagnoses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9bc41d-1789-47ad-9e35-83d0466d53a6",
   "metadata": {},
   "source": [
    "#### Loading and cleaning master table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c41e3fb1-51b7-4861-8ffb-314e7a728543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to print shape and message via .pipe, while returning df to continue data processing\n",
    "def print_shape(df, msg = ''):\n",
    "    print(msg, df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db42ce3-345d-446a-b8f5-fdcb87dd63bf",
   "metadata": {},
   "source": [
    "#### Data pipeline\n",
    "\n",
    "Filters data and merges features while printing shape at every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0711d3f7-7849-440c-9389-79c2ac33efa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape:  (61051, 19)\n",
      "After filtering to sepsis:  (6126, 19)\n",
      "After filtering to first hospital+icu stay:  (3534, 19)\n",
      "After filtering ages:  (3262, 19)\n",
      "After inner-merging on features:  (3169, 102)\n",
      "After dropping rows where >20% features are missing:  (3155, 86)\n",
      "Final shape:  (3155, 92)\n"
     ]
    }
   ],
   "source": [
    "Xy = (\n",
    "    pd.read_csv('mimic_concepts/icustay_detail.csv') # table of all icu stays along with demographic information\n",
    "    .pipe(print_shape, 'Initial shape: ')\n",
    "    .loc[lambda df: df['hadm_id'].isin(sepsis_diagnoses['HADM_ID'])] # sepsis filter\n",
    "    .pipe(print_shape, 'After filtering to sepsis: ')\n",
    "\n",
    "    .loc[lambda df: df['first_hosp_stay']] # only keep first hospital stays\n",
    "    .loc[lambda df: df['first_icu_stay']] # only keep first icu stay info\n",
    "    .pipe(print_shape, 'After filtering to first hospital+icu stay: ')\n",
    "\n",
    "    .loc[lambda df: df['admission_age'].ge(18)] # age filter\n",
    "    .loc[lambda df: df['admission_age'].le(89)] # age filter\n",
    "    .pipe(print_shape, 'After filtering ages: ')\n",
    "\n",
    "    # create y marker\n",
    "    .assign(\n",
    "        death_within_30 = lambda df:\n",
    "        df['hospital_expire_flag']\n",
    "        # if length of stay > 30, mark as not dead within 30 days\n",
    "        .mask(\n",
    "            df['los_hospital'].gt(30),\n",
    "            0\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # inner merge all features. Don't lose too many rows\n",
    "    .merge(\n",
    "        pd.read_csv('mimic_concepts/labs_first_day.csv'),\n",
    "        how='inner',\n",
    "        on = ['subject_id', 'hadm_id', 'icustay_id'],\n",
    "    )\n",
    "    .merge(\n",
    "        pd.read_csv('mimic_concepts/heightweight.csv'),\n",
    "        how='inner',\n",
    "        on = ['icustay_id'],\n",
    "    )\n",
    "    .merge(\n",
    "        pd.read_csv('mimic_concepts/vitals_first_day.csv'),\n",
    "        how='inner', # this drops like 20 rows\n",
    "        on = ['subject_id', 'hadm_id', 'icustay_id'],\n",
    "    ) # deal with conflicting glucose vals\n",
    "    .merge(\n",
    "        pd.read_csv('mimic_concepts/gcs_first_day.csv'),\n",
    "        how='inner',\n",
    "        on = ['subject_id', 'hadm_id', 'icustay_id'],\n",
    "    )\n",
    "    .merge(\n",
    "        pd.read_csv('mimic_concepts/elixhauser_ahrq_v37.csv')\n",
    "        # only keep cols with at least 1% of data. maybe just drop this..\n",
    "        .loc[\n",
    "            :,\n",
    "            lambda df:\n",
    "            df.sum().div(df.shape[0]).gt(0.01)\n",
    "        ],\n",
    "        how='inner',\n",
    "        on = ['subject_id', 'hadm_id'],\n",
    "    )\n",
    "    .merge(\n",
    "        pd.read_csv('mimic_concepts/ventilation_first_day.csv'),\n",
    "        how='inner',\n",
    "        on = ['subject_id', 'hadm_id', 'icustay_id'],\n",
    "    )\n",
    "    .merge(\n",
    "        pd.read_csv('mimic_concepts/rrt_first_day.csv'),\n",
    "        how='inner',\n",
    "        on = ['subject_id', 'hadm_id', 'icustay_id'],\n",
    "    )\n",
    "    .merge(\n",
    "        pd.read_csv('mimic_concepts/urine_output_first_day.csv'),\n",
    "        how='inner', #this drops a few hundred\n",
    "        on = ['subject_id', 'hadm_id', 'icustay_id'],\n",
    "    )\n",
    "    .merge(\n",
    "        pd.read_csv('mimic_concepts/sapsii.csv')[['subject_id', 'hadm_id', 'icustay_id', 'sapsii']],\n",
    "        how='inner', #this drops a few hundred\n",
    "        on = ['subject_id', 'hadm_id', 'icustay_id'],\n",
    "    )\n",
    "    .merge(\n",
    "        pd.read_csv('mimic_concepts/sofa.csv')[['subject_id', 'hadm_id', 'icustay_id', 'SOFA']],\n",
    "        how='inner', #this drops a few hundred\n",
    "        on = ['subject_id', 'hadm_id', 'icustay_id'],\n",
    "    )\n",
    "    .merge(\n",
    "        pd.read_csv('mimic_concepts/qsofa.csv')[['subject_id', 'hadm_id', 'icustay_id', 'qSOFA']],\n",
    "        how='inner', #this drops a few hundred\n",
    "        on = ['subject_id', 'hadm_id', 'icustay_id'],\n",
    "    )\n",
    "    .pipe(print_shape, 'After inner-merging on features: ')\n",
    "\n",
    "\n",
    "    \n",
    "    # drop columns not intended for modeling\n",
    "    .drop(\n",
    "        columns=[\n",
    "            'icustay_id',\n",
    "            'dod',\n",
    "            'admittime',\n",
    "            'dischtime',\n",
    "            'los_hospital',\n",
    "            'ethnicity',\n",
    "            'hospital_expire_flag',\n",
    "            'hospstay_seq',\n",
    "            'first_hosp_stay',\n",
    "            'intime',\n",
    "            'outtime',\n",
    "            'los_icu',\n",
    "            'icustay_seq',\n",
    "            'first_icu_stay',\n",
    "            'subject_id',\n",
    "            'hadm_id'\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # drop rows where >20% features are missing\n",
    "    .loc[\n",
    "        lambda df:\n",
    "        df\n",
    "        .isna()\n",
    "        .sum(axis=1)\n",
    "        .div(df.shape[1]).lt(0.2)\n",
    "    ]\n",
    "    .pipe(print_shape, 'After dropping rows where >20% features are missing: ')\n",
    "\n",
    "\n",
    "\n",
    "    # xgboost can natively handle categorical, and onehot, but maybe in interest of time just do it in pandas\n",
    "    .assign(gender = lambda df: df['gender'].replace({'F':0, 'M': 1}))\n",
    "    .pipe(\n",
    "        lambda df:\n",
    "        pd.concat([\n",
    "            df.drop(columns='ethnicity_grouped'),\n",
    "            df['ethnicity_grouped'].pipe(pd.get_dummies, prefix='ethnicity')\n",
    "        ], axis=1)\n",
    "    )\n",
    "    # .fillna(-1)\n",
    "    \n",
    "    .reset_index(drop=True)\n",
    "    .pipe(print_shape, 'Final shape: ')\n",
    "\n",
    ")\n",
    "# Xy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f24377-d66c-44bf-98fe-c4aede60bcab",
   "metadata": {},
   "source": [
    "#### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "138947fa-138e-4578-b623-5d7a2fd00739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2295\n",
       "1     860\n",
       "Name: death_within_30, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target value counts\n",
    "Xy['death_within_30'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "19ae2096-a69d-46f4-940d-c91929c64101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bands_min        1842\n",
       "bands_max        1842\n",
       "height_first     1565\n",
       "height_max       1563\n",
       "height_min       1563\n",
       "albumin_min      1121\n",
       "albumin_max      1121\n",
       "bilirubin_max     674\n",
       "bilirubin_min     674\n",
       "lactate_max       341\n",
       "lactate_min       341\n",
       "ptt_min           191\n",
       "ptt_max           191\n",
       "pt_max            181\n",
       "pt_min            181\n",
       "inr_max           181\n",
       "inr_min           181\n",
       "gcsmotor           44\n",
       "weight_max         36\n",
       "weight_min         36\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe most commonly missing features\n",
    "Xy.isna().sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b8835e-5db4-44cb-9e62-e04755dfc18c",
   "metadata": {},
   "source": [
    "##   Model\n",
    "<!-- The model includes the model definitation which usually is a class, model training, and other necessary parts.\n",
    "  * Model architecture: layer number/size/type, activation function, etc\n",
    "  * Training objectives: loss function, optimizer, weight of each loss term, etc\n",
    "  * Others: whether the model is pretrained, Monte Carlo simulation for uncertainty analysis, etc\n",
    "  * The code of model should have classes of the model, functions of model training, model validation, etc.\n",
    "  * If your model training is done outside of this notebook, please upload the trained model here and develop a function to load and test it. -->\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a910ab-9fc2-4721-8d03-27acc77bf6fb",
   "metadata": {},
   "source": [
    "### Model description \n",
    "\n",
    "XGBoost is a tree based model that at a high level has many benefits, including the ability to learn nonlinear patterns in the data, and handle categorical and missing values natively. From a technical standpoint, XGBoost is an ensemble model that combines multiple weak learners to obtain better performance. It combines the learners through a framework called gradient boosting, which sequentially builds new models to correct the errors of the previous one. \n",
    "\n",
    "The main comparison model is logistic regression, which is a classical linear classification model. One of the expected limitations of logistic regression is in its linearity, which in theory XGBoost can outperform since it makes no such linearity assumptions. \n",
    "\n",
    "### Hyperparameter tuning, preprocessing, and ablations:\n",
    "\n",
    "I try 16 different combinations of models and preprocessing steps. \n",
    "\n",
    "In particular, for the models I tried logistic regression out of the box as well as logistic regression cv, which optimizes the regularization strength by cross validating over the training data. For XGBoost I tried an out of the box version, a \"tailored\" version I found on the internet, and a gridsearched version of XGBoost which attempted to optimize several key hyperparameters (max_depth, learning_rate, n_estimators, colsample_bytree) by cross validating over the training set.\n",
    "\n",
    "For preprocessing, tried all combinations of scaling the data and imputing missing values with the mean, including no preprocessing. I explored these because I know scaling can be important for regularized linear models like logistic regression, and also that XGBoost can handle missing values natively, so I wanted to see whether or not these preprocessing steps mattered at all for performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf995f82-6df1-403f-baea-7fdf22ce2e35",
   "metadata": {},
   "source": [
    "### Computational requirements\n",
    "\n",
    "The training experiments were run on a 2021 M1 Macbook Pro with 16 gb of memory. \n",
    "\n",
    "Additionally, average fold train time per model type is described below in the Runtimes section, adding up to a total of about 80 minutes for training all in all. \n",
    "\n",
    "Overall, we tried 16 combinations of model and preprocessing steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7903a3ce-bda6-4aef-bc1f-5e75174d4d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = 'death_within_30'\n",
    "X = Xy.drop(columns=[y_col])\n",
    "y = Xy[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2717fd99-4daa-45fc-96a8-d19773af89ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    'logisticregression_out_of_the_box': LogisticRegression(random_state=1),\n",
    "    'logisticregressioncv': LogisticRegressionCV(Cs= 5, max_iter=3000, random_state=1, cv=3, penalty='elasticnet', l1_ratios=[0, 1, 0.5], solver='saga'),\n",
    "    'xgboost_out_of_the_box': XGBClassifier(random_state=1),\n",
    "    'xgboost_gridsearch': GridSearchCV(\n",
    "        estimator=XGBClassifier(random_state=1),\n",
    "            param_grid={\n",
    "                'max_depth': [3, 6, 10],\n",
    "                'learning_rate': [0.01, 0.1, 0.3],\n",
    "                'n_estimators': [500],\n",
    "                'colsample_bytree': [0.35, 0.7]\n",
    "            },\n",
    "            scoring='roc_auc',\n",
    "            cv=3\n",
    "        ),\n",
    "    'xgboost_tailored': XGBClassifier(\n",
    "                learning_rate =0.1,\n",
    "                n_estimators=1000,\n",
    "                max_depth=4,\n",
    "                min_child_weight=6,\n",
    "                gamma=0,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                objective= 'binary:logistic',\n",
    "                nthread=4,\n",
    "                scale_pos_weight=1,\n",
    "                seed=27)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1e3398d7-720b-486c-b084-568b685eab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_steps_dict = {\n",
    "    'scale': [StandardScaler()],\n",
    "    'scale_impute': [StandardScaler(), SimpleImputer()],\n",
    "    'impute': [SimpleImputer()],\n",
    "    'none': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "40810b77-f64f-476e-b80c-f1dc61f35eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logisticregression_out_of_the_box\n",
      "\t scale\n",
      "\t scale_impute\n",
      "\t impute\n",
      "\t none\n",
      "logisticregressioncv\n",
      "\t scale\n",
      "\t scale_impute\n",
      "\t impute\n",
      "\t none\n",
      "xgboost_out_of_the_box\n",
      "\t scale\n",
      "\t scale_impute\n",
      "\t impute\n",
      "\t none\n",
      "xgboost_gridsearch\n",
      "\t scale\n",
      "\t scale_impute\n",
      "\t impute\n",
      "\t none\n",
      "xgboost_tailored\n",
      "\t scale\n",
      "\t scale_impute\n",
      "\t impute\n",
      "\t none\n",
      "CPU times: user 1h 51min 2s, sys: 1h 3min 3s, total: 2h 54min 6s\n",
      "Wall time: 1h 21min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "pred_df = pd.DataFrame()\n",
    "times_df = pd.DataFrame()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for model_name in models_dict:\n",
    "    print(model_name)\n",
    "    for preprocessing_steps_name in preprocessing_steps_dict:\n",
    "        print('\\t', preprocessing_steps_name)\n",
    "        \n",
    "        # skip if not imputing missing values because logistic regression doesn't handle missing out of box\n",
    "        if 'logistic' in model_name and 'impute' not in preprocessing_steps_name:\n",
    "            continue\n",
    "        iteration_name = ':'.join([model_name, preprocessing_steps_name])\n",
    "        \n",
    "        for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "            start_time = time.time()\n",
    "\n",
    "            \n",
    "            X_train = X.iloc[train_index]\n",
    "            y_train = y.iloc[train_index]\n",
    "            X_test = X.iloc[test_index]\n",
    "            y_test = y.iloc[test_index]\n",
    "\n",
    "            model = clone(models_dict[model_name]) # clone the model to make sure it is unfitted\n",
    "            preprocessing_steps = preprocessing_steps_dict[preprocessing_steps_name]\n",
    "            pipeline = make_pipeline(*preprocessing_steps + [model])\n",
    "\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            preds = pipeline.predict(X_test)\n",
    "            pred_probas = pipeline.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            iteration_info_dict = {\n",
    "                'iteration_name': iteration_name,\n",
    "                'model_name': model_name,\n",
    "                'preprocessing_steps': preprocessing_steps_name,\n",
    "            }\n",
    "\n",
    "            pred_df_fold = pd.DataFrame(\n",
    "                iteration_info_dict | {\n",
    "                'y_actual': y_test,\n",
    "                'y_pred': preds,\n",
    "                'y_pred_proba': pred_probas,\n",
    "                'fold': i,\n",
    "                'test_inds': test_index\n",
    "            })\n",
    "            pred_df = pd.concat([pred_df, pred_df_fold])\n",
    "            \n",
    "            end_time = time.time()\n",
    "            runtime = end_time - start_time\n",
    "            time_row = (\n",
    "                pd.Series(iteration_info_dict | {\n",
    "                    'fold': i,\n",
    "                    'fold_runtime': runtime\n",
    "                })\n",
    "                .to_frame()\n",
    "                .T\n",
    "            )\n",
    "            times_df = pd.concat([times_df, time_row])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb44df1-b2c7-4ddb-9bf6-aa6bc1f55765",
   "metadata": {},
   "source": [
    "# Evaluation and Results\n",
    "<!-- In this section, you should finish training your model training or loading your trained model. That is a great experiment! You should share the results with others with necessary metrics and figures.\n",
    "\n",
    "Please test and report results for all experiments that you run with:\n",
    "\n",
    "*   specific numbers (accuracy, AUC, RMSE, etc)\n",
    "*   figures (loss shrinkage, outputs from GAN, annotation or label of sample pictures, etc) -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5e97a8-4857-4fe6-b45f-6a0831c512c9",
   "metadata": {},
   "source": [
    "We record several metrics for our classification task, accuracy, precision, recall, f1 score, and ROC AUC. Each evaluates a different aspect of performance. We will focus on ROC AUC since that is the primary evaluation metric that the original paper used. ROC AUC calculates the Area Under the ROC Curve, where the ROC Curve plots the tradeoff between True Positive Rate and False Positive Rate. The higher the AUC, the better the model. \n",
    "\n",
    "For completeness, we will plot ROC curves for both the best logistic regression model and the best XGboost model, as a visual guide to their performance differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e8d2f0-02de-413f-8b9f-7fc8b05b7c4f",
   "metadata": {},
   "source": [
    "## Main Results Table: \n",
    "\n",
    "Performance of each model+preprocessing step combination.\n",
    "\n",
    "Contrary to the original paper, logistic regression is the best performing model, with ~0.822 AUC, whereas the best XGBoost model attained ~0.817 AUC. It's worthwhile to note that performance discrepancies are not really significant between all of the models. There is less than 0.01 AUC difference between the best logistic regression and the best XGBoost model, while there is about ~0.03 difference between the best and the worst model.\n",
    "\n",
    "Another thing these experiments seem to suggest is that optimizing XGBoost hyperparameters is more important than optimizing logistic regression hyperparameters, and optimizing preprocessing is more important for logistic regression than it is for XGBoost. Through the results table we see that \"xgboost_gridsearch\" outperformed all other iterations of xgboost across all preprocessing steps, while the \"scale_impute\" logistic regression models always perform better than their \"impute\" counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2b08bbc0-0bd7-4efc-bf72-95745927d492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>preprocessing_steps</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logisticregression_out_of_the_box:scale_impute</td>\n",
       "      <td>logisticregression_out_of_the_box</td>\n",
       "      <td>scale_impute</td>\n",
       "      <td>0.794612</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.448837</td>\n",
       "      <td>0.543662</td>\n",
       "      <td>0.82156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logisticregressioncv:scale_impute</td>\n",
       "      <td>logisticregressioncv</td>\n",
       "      <td>scale_impute</td>\n",
       "      <td>0.794929</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.394186</td>\n",
       "      <td>0.511698</td>\n",
       "      <td>0.82029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_gridsearch:scale</td>\n",
       "      <td>xgboost_gridsearch</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.798098</td>\n",
       "      <td>0.743982</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.516325</td>\n",
       "      <td>0.817355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_gridsearch:none</td>\n",
       "      <td>xgboost_gridsearch</td>\n",
       "      <td>none</td>\n",
       "      <td>0.797147</td>\n",
       "      <td>0.740175</td>\n",
       "      <td>0.394186</td>\n",
       "      <td>0.514416</td>\n",
       "      <td>0.816862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_gridsearch:scale_impute</td>\n",
       "      <td>xgboost_gridsearch</td>\n",
       "      <td>scale_impute</td>\n",
       "      <td>0.795563</td>\n",
       "      <td>0.737307</td>\n",
       "      <td>0.388372</td>\n",
       "      <td>0.508759</td>\n",
       "      <td>0.816173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_gridsearch:impute</td>\n",
       "      <td>xgboost_gridsearch</td>\n",
       "      <td>impute</td>\n",
       "      <td>0.794295</td>\n",
       "      <td>0.737079</td>\n",
       "      <td>0.381395</td>\n",
       "      <td>0.502682</td>\n",
       "      <td>0.813867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_tailored:none</td>\n",
       "      <td>xgboost_tailored</td>\n",
       "      <td>none</td>\n",
       "      <td>0.783835</td>\n",
       "      <td>0.638629</td>\n",
       "      <td>0.476744</td>\n",
       "      <td>0.545939</td>\n",
       "      <td>0.812403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_out_of_the_box:scale</td>\n",
       "      <td>xgboost_out_of_the_box</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.785737</td>\n",
       "      <td>0.649837</td>\n",
       "      <td>0.463953</td>\n",
       "      <td>0.541384</td>\n",
       "      <td>0.808331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_out_of_the_box:impute</td>\n",
       "      <td>xgboost_out_of_the_box</td>\n",
       "      <td>impute</td>\n",
       "      <td>0.787639</td>\n",
       "      <td>0.66323</td>\n",
       "      <td>0.448837</td>\n",
       "      <td>0.535368</td>\n",
       "      <td>0.808152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_out_of_the_box:scale_impute</td>\n",
       "      <td>xgboost_out_of_the_box</td>\n",
       "      <td>scale_impute</td>\n",
       "      <td>0.787005</td>\n",
       "      <td>0.653595</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.807813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_out_of_the_box:none</td>\n",
       "      <td>xgboost_out_of_the_box</td>\n",
       "      <td>none</td>\n",
       "      <td>0.787639</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>0.463953</td>\n",
       "      <td>0.543597</td>\n",
       "      <td>0.807811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_tailored:scale_impute</td>\n",
       "      <td>xgboost_tailored</td>\n",
       "      <td>scale_impute</td>\n",
       "      <td>0.776228</td>\n",
       "      <td>0.619195</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.531208</td>\n",
       "      <td>0.807749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_tailored:impute</td>\n",
       "      <td>xgboost_tailored</td>\n",
       "      <td>impute</td>\n",
       "      <td>0.776545</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.468605</td>\n",
       "      <td>0.533422</td>\n",
       "      <td>0.807663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_tailored:scale</td>\n",
       "      <td>xgboost_tailored</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.777813</td>\n",
       "      <td>0.622875</td>\n",
       "      <td>0.468605</td>\n",
       "      <td>0.534837</td>\n",
       "      <td>0.806963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logisticregression_out_of_the_box:impute</td>\n",
       "      <td>logisticregression_out_of_the_box</td>\n",
       "      <td>impute</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>0.666016</td>\n",
       "      <td>0.396512</td>\n",
       "      <td>0.497085</td>\n",
       "      <td>0.802261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logisticregressioncv:impute</td>\n",
       "      <td>logisticregressioncv</td>\n",
       "      <td>impute</td>\n",
       "      <td>0.784152</td>\n",
       "      <td>0.695842</td>\n",
       "      <td>0.369767</td>\n",
       "      <td>0.482916</td>\n",
       "      <td>0.79338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   iteration_name  \\\n",
       "0  logisticregression_out_of_the_box:scale_impute   \n",
       "0               logisticregressioncv:scale_impute   \n",
       "0                        xgboost_gridsearch:scale   \n",
       "0                         xgboost_gridsearch:none   \n",
       "0                 xgboost_gridsearch:scale_impute   \n",
       "0                       xgboost_gridsearch:impute   \n",
       "0                           xgboost_tailored:none   \n",
       "0                    xgboost_out_of_the_box:scale   \n",
       "0                   xgboost_out_of_the_box:impute   \n",
       "0             xgboost_out_of_the_box:scale_impute   \n",
       "0                     xgboost_out_of_the_box:none   \n",
       "0                   xgboost_tailored:scale_impute   \n",
       "0                         xgboost_tailored:impute   \n",
       "0                          xgboost_tailored:scale   \n",
       "0        logisticregression_out_of_the_box:impute   \n",
       "0                     logisticregressioncv:impute   \n",
       "\n",
       "                          model_name preprocessing_steps  accuracy precision  \\\n",
       "0  logisticregression_out_of_the_box        scale_impute  0.794612  0.689286   \n",
       "0               logisticregressioncv        scale_impute  0.794929  0.729032   \n",
       "0                 xgboost_gridsearch               scale  0.798098  0.743982   \n",
       "0                 xgboost_gridsearch                none  0.797147  0.740175   \n",
       "0                 xgboost_gridsearch        scale_impute  0.795563  0.737307   \n",
       "0                 xgboost_gridsearch              impute  0.794295  0.737079   \n",
       "0                   xgboost_tailored                none  0.783835  0.638629   \n",
       "0             xgboost_out_of_the_box               scale  0.785737  0.649837   \n",
       "0             xgboost_out_of_the_box              impute  0.787639   0.66323   \n",
       "0             xgboost_out_of_the_box        scale_impute  0.787005  0.653595   \n",
       "0             xgboost_out_of_the_box                none  0.787639   0.65625   \n",
       "0                   xgboost_tailored        scale_impute  0.776228  0.619195   \n",
       "0                   xgboost_tailored              impute  0.776545  0.619048   \n",
       "0                   xgboost_tailored               scale  0.777813  0.622875   \n",
       "0  logisticregression_out_of_the_box              impute    0.7813  0.666016   \n",
       "0               logisticregressioncv              impute  0.784152  0.695842   \n",
       "\n",
       "     recall        f1   ROC_AUC  \n",
       "0  0.448837  0.543662   0.82156  \n",
       "0  0.394186  0.511698   0.82029  \n",
       "0  0.395349  0.516325  0.817355  \n",
       "0  0.394186  0.514416  0.816862  \n",
       "0  0.388372  0.508759  0.816173  \n",
       "0  0.381395  0.502682  0.813867  \n",
       "0  0.476744  0.545939  0.812403  \n",
       "0  0.463953  0.541384  0.808331  \n",
       "0  0.448837  0.535368  0.808152  \n",
       "0  0.465116  0.543478  0.807813  \n",
       "0  0.463953  0.543597  0.807811  \n",
       "0  0.465116  0.531208  0.807749  \n",
       "0  0.468605  0.533422  0.807663  \n",
       "0  0.468605  0.534837  0.806963  \n",
       "0  0.396512  0.497085  0.802261  \n",
       "0  0.369767  0.482916   0.79338  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration_summary_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for iteration_name in pred_df['iteration_name'].unique():\n",
    "    pred_df_iteration = pred_df.loc[lambda df: df['iteration_name'].eq(iteration_name)]\n",
    "    model_name, preprocessing_steps_name = iteration_name.split(':')\n",
    "    \n",
    "    iteration_summary_row = (\n",
    "        pd.Series({\n",
    "            'iteration_name': iteration_name,\n",
    "            'model_name': model_name,\n",
    "            'preprocessing_steps': preprocessing_steps_name,\n",
    "            'accuracy': metrics.accuracy_score(pred_df_iteration['y_actual'], pred_df_iteration['y_pred']),\n",
    "            'precision': metrics.precision_score(pred_df_iteration['y_actual'], pred_df_iteration['y_pred']),\n",
    "            'recall': metrics.recall_score(pred_df_iteration['y_actual'], pred_df_iteration['y_pred']),\n",
    "            'f1': metrics.f1_score(pred_df_iteration['y_actual'], pred_df_iteration['y_pred']),\n",
    "            'ROC_AUC': metrics.roc_auc_score(pred_df_iteration['y_actual'], pred_df_iteration['y_pred_proba']),\n",
    "        })\n",
    "        .to_frame()\n",
    "        .T\n",
    "    )\n",
    "    \n",
    "    iteration_summary_df = pd.concat([iteration_summary_df, iteration_summary_row])\n",
    "\n",
    "    \n",
    "iteration_summary_df = iteration_summary_df.sort_values('ROC_AUC', ascending=False)\n",
    "iteration_summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f51b666-040d-4687-a974-dbffc66f78e0",
   "metadata": {},
   "source": [
    "## Model deep dives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "308f4dd5-9de2-4a9c-8aac-1b86a4720610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>preprocessing_steps</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logisticregression_out_of_the_box:scale_impute</td>\n",
       "      <td>logisticregression_out_of_the_box</td>\n",
       "      <td>scale_impute</td>\n",
       "      <td>0.794612</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.448837</td>\n",
       "      <td>0.543662</td>\n",
       "      <td>0.82156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   iteration_name  \\\n",
       "0  logisticregression_out_of_the_box:scale_impute   \n",
       "\n",
       "                          model_name preprocessing_steps  accuracy precision  \\\n",
       "0  logisticregression_out_of_the_box        scale_impute  0.794612  0.689286   \n",
       "\n",
       "     recall        f1  ROC_AUC  \n",
       "0  0.448837  0.543662  0.82156  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best logistic regression model \n",
    "best_logistic_regression_iteration_row = iteration_summary_df.loc[lambda df: df['model_name'].str.contains('logistic')].iloc[[0]]\n",
    "best_logistic_regression_iteration = best_logistic_regression_iteration_row['iteration_name'].values[0]\n",
    "best_logistic_regression_iteration_pred_df = pred_df.loc[lambda df: df['iteration_name'].eq(best_logistic_regression_iteration)]\n",
    "\n",
    "best_logistic_regression_iteration_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7452c1a4-6a94-4a47-a206-d9bafda773a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>preprocessing_steps</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_gridsearch:scale</td>\n",
       "      <td>xgboost_gridsearch</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.798098</td>\n",
       "      <td>0.743982</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.516325</td>\n",
       "      <td>0.817355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             iteration_name          model_name preprocessing_steps  accuracy  \\\n",
       "0  xgboost_gridsearch:scale  xgboost_gridsearch               scale  0.798098   \n",
       "\n",
       "  precision    recall        f1   ROC_AUC  \n",
       "0  0.743982  0.395349  0.516325  0.817355  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best xgboost model \n",
    "best_xgb_iteration_row = iteration_summary_df.loc[lambda df: df['model_name'].str.contains('xgb')].iloc[[0]]\n",
    "best_xgb_iteration = best_xgb_iteration_row['iteration_name'].values[0]\n",
    "best_xgb_iteration_pred_df = pred_df.loc[lambda df: df['iteration_name'].eq(best_xgb_iteration)]\n",
    "best_xgb_iteration_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe64b12-58ee-4c28-b25c-f0e0c81da39f",
   "metadata": {},
   "source": [
    "#### ROC metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972067b-b743-4711-af96-55e87b3d6a44",
   "metadata": {},
   "source": [
    "Here we overlay the ROC curves of the best logistic regression model and the best XGBoost model. Visually they look very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f8941a93-950b-4c77-8a88-89f87f4da1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28c605bb0>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 9))\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(best_xgb_iteration_pred_df['y_actual'], best_xgb_iteration_pred_df['y_pred_proba'])\n",
    "auc = metrics.roc_auc_score(best_xgb_iteration_pred_df['y_actual'], best_xgb_iteration_pred_df['y_pred_proba'])\n",
    "plt.plot(fpr,tpr,label=f'Best XGBoost model, auc={auc:.2f}')\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(best_logistic_regression_iteration_pred_df['y_actual'], best_logistic_regression_iteration_pred_df['y_pred_proba'])\n",
    "auc = metrics.roc_auc_score(best_logistic_regression_iteration_pred_df['y_actual'], best_logistic_regression_iteration_pred_df['y_pred_proba'])\n",
    "plt.plot(fpr,tpr,label=f'Best Logistic regression model, auc={auc:.2f}')\n",
    "\n",
    "ax.set_title('ROC Curve')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254962b1-8a96-4011-8422-381b7ca53ec2",
   "metadata": {},
   "source": [
    "## Runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c1269-9fcb-49cb-80e5-a6e8c806c852",
   "metadata": {},
   "source": [
    "See below average fold runtime for each of the model+preprocessing combinations tried. The gridsearched XGBoost model clearly took the most time, since it had to search over several parameters using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d8f2d3b2-df7c-4268-b1a8-def40e27fd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>preprocessing_steps</th>\n",
       "      <th>total_iteration_runtime</th>\n",
       "      <th>mean_fold_runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logisticregression_out_of_the_box:impute</td>\n",
       "      <td>logisticregression_out_of_the_box</td>\n",
       "      <td>impute</td>\n",
       "      <td>0.672642</td>\n",
       "      <td>0.134528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logisticregression_out_of_the_box:scale_impute</td>\n",
       "      <td>logisticregression_out_of_the_box</td>\n",
       "      <td>scale_impute</td>\n",
       "      <td>0.573674</td>\n",
       "      <td>0.114735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logisticregressioncv:impute</td>\n",
       "      <td>logisticregressioncv</td>\n",
       "      <td>impute</td>\n",
       "      <td>190.451209</td>\n",
       "      <td>38.090242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logisticregressioncv:scale_impute</td>\n",
       "      <td>logisticregressioncv</td>\n",
       "      <td>scale_impute</td>\n",
       "      <td>179.757807</td>\n",
       "      <td>35.951561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xgboost_gridsearch:impute</td>\n",
       "      <td>xgboost_gridsearch</td>\n",
       "      <td>impute</td>\n",
       "      <td>1100.207111</td>\n",
       "      <td>220.041422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgboost_gridsearch:none</td>\n",
       "      <td>xgboost_gridsearch</td>\n",
       "      <td>none</td>\n",
       "      <td>1186.618116</td>\n",
       "      <td>237.323623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgboost_gridsearch:scale</td>\n",
       "      <td>xgboost_gridsearch</td>\n",
       "      <td>scale</td>\n",
       "      <td>1057.332465</td>\n",
       "      <td>211.466493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xgboost_gridsearch:scale_impute</td>\n",
       "      <td>xgboost_gridsearch</td>\n",
       "      <td>scale_impute</td>\n",
       "      <td>1086.061112</td>\n",
       "      <td>217.212222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xgboost_out_of_the_box:impute</td>\n",
       "      <td>xgboost_out_of_the_box</td>\n",
       "      <td>impute</td>\n",
       "      <td>4.622737</td>\n",
       "      <td>0.924547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xgboost_out_of_the_box:none</td>\n",
       "      <td>xgboost_out_of_the_box</td>\n",
       "      <td>none</td>\n",
       "      <td>10.527162</td>\n",
       "      <td>2.105432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xgboost_out_of_the_box:scale</td>\n",
       "      <td>xgboost_out_of_the_box</td>\n",
       "      <td>scale</td>\n",
       "      <td>5.230286</td>\n",
       "      <td>1.046057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xgboost_out_of_the_box:scale_impute</td>\n",
       "      <td>xgboost_out_of_the_box</td>\n",
       "      <td>scale_impute</td>\n",
       "      <td>4.792217</td>\n",
       "      <td>0.958443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xgboost_tailored:impute</td>\n",
       "      <td>xgboost_tailored</td>\n",
       "      <td>impute</td>\n",
       "      <td>8.190804</td>\n",
       "      <td>1.638161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xgboost_tailored:none</td>\n",
       "      <td>xgboost_tailored</td>\n",
       "      <td>none</td>\n",
       "      <td>10.484264</td>\n",
       "      <td>2.096853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xgboost_tailored:scale</td>\n",
       "      <td>xgboost_tailored</td>\n",
       "      <td>scale</td>\n",
       "      <td>8.97249</td>\n",
       "      <td>1.794498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xgboost_tailored:scale_impute</td>\n",
       "      <td>xgboost_tailored</td>\n",
       "      <td>scale_impute</td>\n",
       "      <td>8.82999</td>\n",
       "      <td>1.765998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    iteration_name  \\\n",
       "0         logisticregression_out_of_the_box:impute   \n",
       "1   logisticregression_out_of_the_box:scale_impute   \n",
       "2                      logisticregressioncv:impute   \n",
       "3                logisticregressioncv:scale_impute   \n",
       "4                        xgboost_gridsearch:impute   \n",
       "5                          xgboost_gridsearch:none   \n",
       "6                         xgboost_gridsearch:scale   \n",
       "7                  xgboost_gridsearch:scale_impute   \n",
       "8                    xgboost_out_of_the_box:impute   \n",
       "9                      xgboost_out_of_the_box:none   \n",
       "10                    xgboost_out_of_the_box:scale   \n",
       "11             xgboost_out_of_the_box:scale_impute   \n",
       "12                         xgboost_tailored:impute   \n",
       "13                           xgboost_tailored:none   \n",
       "14                          xgboost_tailored:scale   \n",
       "15                   xgboost_tailored:scale_impute   \n",
       "\n",
       "                           model_name preprocessing_steps  \\\n",
       "0   logisticregression_out_of_the_box              impute   \n",
       "1   logisticregression_out_of_the_box        scale_impute   \n",
       "2                logisticregressioncv              impute   \n",
       "3                logisticregressioncv        scale_impute   \n",
       "4                  xgboost_gridsearch              impute   \n",
       "5                  xgboost_gridsearch                none   \n",
       "6                  xgboost_gridsearch               scale   \n",
       "7                  xgboost_gridsearch        scale_impute   \n",
       "8              xgboost_out_of_the_box              impute   \n",
       "9              xgboost_out_of_the_box                none   \n",
       "10             xgboost_out_of_the_box               scale   \n",
       "11             xgboost_out_of_the_box        scale_impute   \n",
       "12                   xgboost_tailored              impute   \n",
       "13                   xgboost_tailored                none   \n",
       "14                   xgboost_tailored               scale   \n",
       "15                   xgboost_tailored        scale_impute   \n",
       "\n",
       "   total_iteration_runtime  mean_fold_runtime  \n",
       "0                 0.672642           0.134528  \n",
       "1                 0.573674           0.114735  \n",
       "2               190.451209          38.090242  \n",
       "3               179.757807          35.951561  \n",
       "4              1100.207111         220.041422  \n",
       "5              1186.618116         237.323623  \n",
       "6              1057.332465         211.466493  \n",
       "7              1086.061112         217.212222  \n",
       "8                 4.622737           0.924547  \n",
       "9                10.527162           2.105432  \n",
       "10                5.230286           1.046057  \n",
       "11                4.792217           0.958443  \n",
       "12                8.190804           1.638161  \n",
       "13               10.484264           2.096853  \n",
       "14                 8.97249           1.794498  \n",
       "15                 8.82999           1.765998  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    times_df\n",
    "    .groupby([\n",
    "        'iteration_name',\n",
    "        'model_name',\n",
    "        'preprocessing_steps',\n",
    "    ])\n",
    "    ['fold_runtime']\n",
    "    .agg(\n",
    "        total_iteration_runtime = 'sum',\n",
    "        mean_fold_runtime = 'mean'\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e978869-83ff-47fe-a781-0b50ed93fef8",
   "metadata": {},
   "source": [
    "Total experiment runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7d8f6022-d37b-4f4c-9b0d-838bb300a250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 81.05540145635605 min\n"
     ]
    }
   ],
   "source": [
    "total_runtime = times_df['fold_runtime'].sum()\n",
    "print('Total runtime:', total_runtime/60, 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127496b-58f4-4094-93cd-7b36cad9d133",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "<!-- In this section,you should discuss your work and make future plan. The discussion should address the following questions:\n",
    "  * Make assessment that the paper is reproducible or not.\n",
    "  * Explain why it is not reproducible if your results are kind negative.\n",
    "  * Describe “What was easy” and “What was difficult” during the reproduction.\n",
    "  * Make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
    "  * What will you do in next phase. -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ba0b24-ca02-46b8-b018-698d4bfd0f82",
   "metadata": {},
   "source": [
    "Through all my experiments, I was not able to achieve the performance that the original paper did. The original paper achieved ~0.85 AUC. In my draft I obtained .806 AUC with XGBoost configuration I found on the internet. After optimizing my XGBoost by playing with combinations of missing value imputation as well as gridsearching over parameters, I did obtain a better performance, reaching 0.817 AUC, but still not as good as quoted in the original paper. Nevertheless, performance is still much better than random, which indicates that these models could still be useful in a clinical setting (if deployed appropriately).\n",
    "\n",
    "In terms of what was difficult, I underestimated how much work it was going to be to process the data to be ready for modeling. There is a lot of feature engineering required on the raw data to get it into a state that is ready for modeling. In particular, the raw CHARTEVENTS table is quite large (~30 gb uncompressed) and understandably has most of the rich features, but its size makes it quite difficult to deal with on a compute station like a laptop. Thankfully, I was able to find and leverage several precomputed derived tables on BigQuery to make the feature engineering process smoother. \n",
    "\n",
    "Once the data was processed and ready, the modeling was the easy part. At least with respect to trying out of the box versions of XGBoost and logistic regression and evaluating their performance. It got trickier again once I had to try and optimize the performance of these models.\n",
    "\n",
    "As a suggestion for the authors, the single most important thing the authors could do to improve reproducibility would be to release their code. This could clear things up across the whole process, from the way they train the model to the way they ingest and process the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d655dac9-845e-40fb-8679-b17f11190f2a",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. Hou, N., Li, M., He, L. et al. Predicting 30-days mortality for MIMIC-III patients with sepsis-3: a machine learning approach using XGboost. J Transl Med 18, 462 (2020). https://doi.org/10.1186/s12967-020-02620-5\n",
    "2. Johnson, A., Pollard, T., & Mark, R. (2016). MIMIC-III Clinical Database (version 1.4). PhysioNet. https://doi.org/10.13026/C2XW26.\n",
    "3. Johnson, A. E. W., Pollard, T. J., Shen, L., Lehman, L. H., Feng, M., Ghassemi, M., Moody, B., Szolovits, P., Celi, L. A., & Mark, R. G. (2016). MIMIC-III, a freely accessible critical care database. Scientific Data, 3, 160035.\n",
    "4. Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C., Mark, R., ... & Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation [Online]. 101 (23), pp. e215–e220.\n",
    "5. Jain, Aarshay. “XGBoost Parameters Tuning | Complete Guide With Python Codes.” Analytics Vidhya, 07 Jan 2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d036555c-5e12-4cd1-96f2-64dc0eaf7be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
